# 챕터9
## 메인메모리
챕터5에서, 우리는 CPU가 프로세스의 집합에 의해 어떻게 공유되는지 살펴봤다. CPU 스케줄링의 결과로 우리는 CPU 이용률과 컴퓨터를 사용하는 사람들에 대한 컴퓨터의 응답속도를 향상시킬 수 있었다. 하지만 이런 성능의 향상을 실형하기 위해서는 많은 프로세스들을 메모리에 유지해야하고, 결국 메모리를 공유해야 한다.

이 챕터에서는 우리는 메모리를 관리하는 다양한 방법에 대해 알아볼 것이다. 메모리 관리 알고리즘은 원시적인 배어 머신 접근법부터 페이징을 사용하는 전략까지 다양하다. 각 접근법은 각 장단점을 가지고 있다. 특정 시스템을 위해 메모리 관리 방법을 선택하는 것은 다양한 요인들에 의존한다. 특히 시스템의 하드웨어 디자인에 의존한다. 보다시피, 대부분의 알고리즘은 하드웨어 지원을 필요로 하며, 이로 인해 많은 시스템은 하드웨어와 운영 체제 메모리 관리를 밀접하게 통합하게 한다.

### 챕터 목표
- 논리적 주소와 물리적 주소의 차이점을 설명하고 주소를 바꾸는 과정에 있어서 메모리 관리 유닛(MMU)의 역할을 설명한다. MMU(memory management unit)
- 메모리를 연속적으로 할당하기 위한 최초와 최적과 최악의 전략을 적용해본다.
- 내부 단편화와 외부 단편화의 차이를 설명한다.
- TLB를 포함하고 있는 페이징 시스템에서 논리적 주소를 물리적 주소로 변환한다. TLB(translation look-aside buffer)
- 계층구조인 페이징, 해시된 페이징, 반전된 페이지 테이블을 설명한다.
- IA-32, x86-64, 그리고 ARMv8 구조에서의 주소 변환에 대해 설명한다.

### 9.1 배경
챕터 1에서 봤듯이, 메모리는 현대 컴퓨터 시스템의 동작에서 중요한 부분이다. 메모리는 byte의 큰 배열로 구성되어 있고 각각의 byte는 자신만의 주소를 가지고 있다. CPU는 프로그램 카운터의 값에 따라 메모리에서 명령어들을 가져온다. 이 명령어들은 특정 메모리 주소로부터 추가적인 로딩과 저장을 일으킬 수 있다.

전형적인 명령어-실행 사이클을 예로 들면, 먼저 메모리로부터 명령어를 가져온다. 명령어는 디코드되고 피연산자(operands)가 메모리로부터 가져와지는 걸 일으킬 수 있다. 명령어가 피연산자에 대해 실행된 후, 결과는 다시 메모리에 저장될 수 있다. 메모리 장치(memory unit)는 오직 메모리 주소들의 스트림만 본다; 메모리 장치는 메모리 주소들이 어떻게 생성되었는지(명령어 카운터에 의한 것인지, 인덱싱에 의한 것인지, indirection에 의한 것인지, literal addresses들인지, 기타 등등인지) 알지 못한다. 또는 명령어들을 위한 주소인지, 데이터를 위한 주소인지도 알지 못한다. 따라서 우리는 프로그램이 메모리 주소를 어떻게 생성했는지는 무시할 수 있다. 우리는 오직 실행 중인 프로그램이 생성하는 메로리 주소들의 순서에만 관심이 있다.

우리는 메모리를 관리하는데 적절한 몇가지 이슈를 다루면서 이야기를 시작할 것이다. 기본 하드웨어(basic hardware), symbolic 메모리나 가성 메모리 주소를 실제 물리적 주소에 연결하는 일, 그리고 논리적 주소와 물리적 주소의 구분이 그 이슈다. 그리고 dynamic linking과 shared libraries에 대한 논의로 이 섹션을 마무리한다.
