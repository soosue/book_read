# 챕터9
## 메인메모리
챕터5에서, 우리는 CPU가 프로세스의 집합에 의해 어떻게 공유되는지 살펴봤다. CPU 스케줄링의 결과로 우리는 CPU 이용률과 컴퓨터를 사용하는 사람들에 대한 컴퓨터의 응답속도를 향상시킬 수 있었다. 하지만 이런 성능의 향상을 실형하기 위해서는 많은 프로세스들을 메모리에 유지해야하고, 결국 메모리를 공유해야 한다.

이 챕터에서는 우리는 메모리를 관리하는 다양한 방법에 대해 알아볼 것이다. 메모리 관리 알고리즘은 원시적인 배어 머신 접근법부터 페이징을 사용하는 전략까지 다양하다. 각 접근법은 각 장단점을 가지고 있다. 특정 시스템을 위해 메모리 관리 방법을 선택하는 것은 다양한 요인들에 의존한다. 특히 시스템의 하드웨어 디자인에 의존한다. 보다시피, 대부분의 알고리즘은 하드웨어 지원을 필요로 하며, 이로 인해 많은 시스템은 하드웨어와 운영 체제 메모리 관리를 밀접하게 통합하게 한다.

### 챕터 목표
- 논리적 주소와 물리적 주소의 차이점을 설명하고 주소를 바꾸는 과정에 있어서 메모리 관리 유닛(MMU)의 역할을 설명한다. MMU(memory management unit)
- 메모리를 연속적으로 할당하기 위한 최초와 최적과 최악의 전략을 적용해본다.
- 내부 단편화와 외부 단편화의 차이를 설명한다.
- TLB를 포함하고 있는 페이징 시스템에서 논리적 주소를 물리적 주소로 변환한다. TLB(translation look-aside buffer)
- 계층구조인 페이징, 해시된 페이징, 반전된 페이지 테이블을 설명한다.
- IA-32, x86-64, 그리고 ARMv8 구조에서의 주소 변환에 대해 설명한다.

