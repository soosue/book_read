# 3.1 카프카 기초 다지기

## 카프카를 구성하는 주요 요소
- 주키퍼(ZooKeeper): 아파치 프로젝트 애플리케이션 이름이다. 카프카의 메타데이터 관리 및 브로커의 정상상태 점검(health check)을 담당한다.
- 카프카(Kafka) 또는 카프카 클러스터(Kafka cluster): 아파치 프로젝트 애플리케이션 이름이다. 여러 대의 브로커를 구성한 클러스터를 의미한다.
- 브로커(broker): 카프카 애플리케이션이 설치된 서버 또는 노드를 말한다.
- 프로듀서(producer): 카프카로 메시지를 보내는 역할을 하는 클라이언트를 총칭한다.
- 컨슈머(consumer): 카프카에서 메시지를 꺼내가는 역할을 하는 클라이어늩를 총칭한다.
- 토픽(topic): 카프카는 메시지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유하다.
- 파티션(partition): 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것을 말한다.
- 세그먼트(segment): 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일을 말한다.
- 메시지(message) 또는 레코드(record): 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각을 말한다.

### 3.1.1 리플리케이션

카프카에서 리플리케이션(replication)이란 각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작을 의미한다. 이러한 리플리케이션 동작 덕분에 하나의 브로커가 종료되더라도 카프카는 안정성을 유지할 수 있다.

토픽 생성 명령어 중 replication-factor라는 옵션은 카프카 내 몇 개의 리플리케이션을 유지하겠다는 의미이다. replication-factor가 1이라면 리플리케이션이 1개 있다는 뜻이며, 3이라면 원본을 포함한 리플리케이션이 총 3개가 있다는 뜻이다.
? 브로커가 1일 때, 리플리케이션 1이면 어떻게 되는건지?

카프카에서 토픽이 리플리케이션되는 것이 아니라 토픽의 파티션이 리플리케이션되는 것이다.

안정성을 목적으로 모든 토픽에 대해 각 3개의 리플리케이션으로 설정할 수 있습니다. 리플리케이션 팩터 수가 커지면 안정성은 높아지지만 안정성은 높아지지만 그만큼 브로커 리소스를 많이 사용하게 된다. 따라서 복제에 대한 오버헤드를 줄여서 최대한 브로커를 효율적으로 사용하는 것을 권장한다. 토픽 생성 시 다음과 같이 기준을 세워두고 리플리케이션 팩터 수를 설정해 사용한다면 좀 더 효율적으로 카프카를 운영할 수 있다.
- 테스트나 개발 환경: 팩터 수 1
- 운영 환경(로그성 메시지로서 약간의 유실 허용): 2
- 운영 환경(유실 허용하지 않음): 3

물론 안정성을 더욱 높이고자 하는 경우 리플리케이션 팩터 수를 4나 5 이상으로도 설정할 수 있지만, 운영 경험에 비춰보면 3일 경우에 충분히 메시지 안정성도 보장하고, 적절한 디스크 공간을 사용할 수 있다.

### 3.1.2 파티션

하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하게 만든 것을 파티션(partition)이라고 한다. 이렇게 하나를 여러 개로 나누면 분산 처리도 가능하다. 이렇게 나뉜 파티션 수만큼 컨슈머를 연결할수 있다. 파티션 번호는 0부터 시작한다.

파티션 수도 토픽을 생성할 때 옵션으로 설정하게 되는데, 파티션 수를 정하는 기준은 다소 모호한 경우가 많다. 인터넷에서 자료를 검색해보면 적절한 파티션 수를 구하는 공식도 간혹 있지만, 각 메시지 크기나 초당 메시지 건수 등에 따라 달라지므로 정확하게 예측하기는 어렵다. 특히 파티션 수는 초기 생성 후 언제든지 늘릴 수 있지만, 반대로 한 번 늘린 파티션 수는 절대로 줄일 수 없다는 점을 반드시 명심 해야한다. 따라서 초기에 토픽을 생성할 때 파티션 수를 작게, 즉 2 또는 4 정도로 생성한 후, 메시지 처리량이나 컨슈머의 LAG 등을 모니터링하면서 조금씩 늘려가는 방법이 가장 좋다. 여기서 컨슈머의 LAG이란 '프로듀서가 보낸 메시지 수(카프카에 남아 있는 메시지 수) - 컨슈머가 가져간 메시지 수'를 나타낸다. 컨슈머가 지연 없이 모든 메시지를 가져갔다면 0이다. 따라서 LAG이라는 지표를 통해 컨슈머에 지연이 없는지 확인할 수 있다.

LAG 모니터링 방법은 7장

참고) 적절한 파티션 수 계산 공식은 컨플루언트 사이트(https://eventsizer.io)를 참고해 적절한 파티션 수를 산정해볼 수 있다.

### 3.1.3 세그먼트

카프카에서는 각 메시지들을 저장한다. 프로듀서를 이용해 보낸 메시지는 토픽의 파티션0에 저장된다. 이처럼 프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장되며, 각 메시지들은 세그먼트(segment)라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장된다.
`cd /data/kafka-logs`의 파일 리스트를 확인하면, 특정 토픽의 파티션 디렉토리를 확인할 수 있으며, 해당 디렉토리의 파일 중 log파일에서 hexdump를 보여주는 xxd 명령어를 이용해 내용 중에서 보낸 메시지를 확인할 수 있다.

정리하면,
1. 프로듀서는 카프카의 토픽으로 메시지를 전송한다.
2. 토픽은 프로듀서로부터 받은 메시지를 파티션의 세그먼트 로그 파일에 저장한다.
3. 브로커의 세그먼트 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있다.

컨슈머는 토픽을 컨슘해서 해당 토픽 내 파티션0의 세그먼트 로그 파일에서 메시지를 가져온다.

# 3.2 카프카의 핵심 개념

카프카는 높은 처리량, 빠른 응답 속도, 안정성 때문에 많은 우수한 기업들에게 사용되고 있다. 카프카가 높은 처리량, 안정성을 지니게 된 특성에 대해 알아보도록 하자.

### 3.2.1 분산 시스템

카프카도 분산 시스템이기 때문에, 처음 구성한 클러스터의 리소스가 한계치에 도달하더라도 브로커를 추가하는 방식으로 확장이 가능하다. 카프카에서는 브로커를 온라인 상태에서 매우 간단하게 추가할 수 있다.

### 3.2.2 페이지 캐시

카프카는 OS의 페이지 캐시를 활용하는 방식으로 설계되어 있다. 페이지 캐시는 직접 디스크에 읽고 쓰는 것이 아닌 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용한다. 디스크 I/O에 대한 접근이 줄어드니 성능은 높아진다.

### 3.2.3 배치 전송 처리

카프카는 프로듀서, 컨슈머 클라이언트들과 통신을 하는데 메시지를 주고 받는데 이때 단건 전송이 아닌 배치 전송을 통해 네트워크 오버헤드를 줄이는 방법을 권장한다. 예를 들어 온라인 상품 구매 프로세스에서 상품의 재고 수량 업데이트 작업과 구매 로그를 저장소로 보내는 작업이 있다면, 상품의 재고 수량 업데이트 작업은 지연없이 실시간 처리를 해야하고, 구매 로그를 저장소로 보내는 작업은 배치 처리를 하는 편이 효율적이다.

### 3.2.4 압축 전송

카프카는 메시지 전송 시 좀 더 성능이 높은 압축 전송을 사용하는 것을 권장한다. 배치 전송과 결합해 사용되면 효과가 더 좋다.(파일 하나를 압축하는 것 보단, 비슷한 파일 여러 개를 압축하는 쪽이 효율이 더 좋기 때문이다)

압축 타입에 따라 특성이 있다.
- 높은 압축률: gzip, zstd
- 빠른 응답 속도: lz4, snappy

하지만 실제는 메시지 형식이나 크기에 따라 다를 수 있으므로 실제로 메시지 전송하면서 테스트를 해보고 결정하는 것이 좋다.

### 3.2.5 토픽, 파티션, 오프셋

카프카는 토픽이라는 곳에 데이터를 저장하고, 토픽은 병렬 처리를 위해 파티션이라는 단위로 다시 나뉜다. 파티션을 통해 하나의 토픽이라도 높은 처리량을 수행할 수 있다.

파티션에서 메시지가 저장되는 위치는 오프셋이라고 부르며, 오프셋은 순차 증가하는 숫자(64비트 정수)이다. 오프셋은 파티션별로 고유하며, 메시지의 순서를 보장하고, 컨슈머에서 마지막까지 읽은 위치를 오프셋을 이용해 파악한다.

### 3.2.6 고가용성 보장

카프카는 분산 시스템이기 때무에 하나의 브로커가 다운되어도 다른 브로커가 역할을 대신해 안정적인 서비스가 가능하다. 이런 고가용성을 보장하기 위해 리플리케이션 기능을 제공한다. 리플리케이션 기능은 토픽 자체가 아닌 토픽의 파티션을 복제한다. 토픽 생성시에 옵션으로 리플리케이션 팩터 수를 지정할 수 있다.

원본을 리더, 리플리케이션을 팔로워라고 부른다. 일반적으로 팔로워의 수는 3으로 구성하도록 권장한다. 리더는 프로듀서, 컨슈머로부터 오는 모든 읽기, 쓰기 요청을 처리하며, 팔로워는 오직 리더로부터 리플리케이션한다.

세부내용은 4장

### 3.2.7 주키퍼의 의존성

주키퍼는 아파치 산하 많은 분산 애플리케이션에서 코디네이터 역할을 하는 애플리케이션으로 사용되고 있다.

주키퍼는 여러 대의 서버를 앙상블(클러스터)로 구성하고, 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조이다. 따라서 주키퍼는 반드시 홀수로 구성해야 한다.

지노드(znode)를 이용해 카프카의 메타 정보가 주키퍼에 기록되며, 주키퍼는 이러한 지노드를 이용해 브로커의 노드 관리, 토픽 관리, 컨트롤러 관리 등 매우 중요한 역할을 하고 있다.

현재는 카프카가 성장하면서 주키퍼 성능의 한계가 드러나기 시작했고, 의존성을 없애기 위해 진행 중이다.

카프카의 중요한 메타데이터를 저장하고 각 브로커를 관리하는 중요한 역할을 주키퍼가 한다.

정리하면, 카프카는 여러가지 특성을 가지고 있고 이 특성들은 높은 처리량과, 안정성을 가지게 해준다.
1. 분산 시스템이기 때문에, 안정성을 가지고 있고, 확장에 유연하여 높은 처리량을 가질 수 있게 된다.
2. 페이지 캐시를 이용하기 때문에 디스크 I/O 접근이 줄어들어 높은 처리량을 가지게 된다.
3. 배치 전송 처리를 할 수 있어서 높은 처리량을 가지게 된다.
4. 메시지를 압축해서 전송하기 때문에 높은 처리량을 가지게 된다.
5. 토픽, 파티션, 오프셋 기능을 가지고 있기 때문에 안정성과 높은 처리량을 가지게 된다.
6. 리플리케이션이 있어서 안정성을 가지게 된다.

# 3.3 프로듀서의 기본 동작과 예제 맛보기

### 3.3.1 프로듀서 디자인

프로듀서가 카프카에게 레코드(실제 데이터)를 보낸다. 레코드는 아래 4가지로 구성된다.

1. 토픽
2. 파티션
3. 키
4. 밸류

프로듀서는 카프카에게 메시지를 보낼 때, 특정 토픽으로 보내므로 **토픽과 밸류는 필수값**이다.

**특정 파티션을 지정하기 위한 파티션 값**과, **특정 파티션에 레코드들을 정렬하기 위한 키 값**은 **선택사항**이다.

각 레코드들은 `send()`메소드를 통해 시리얼라이저와 파티셔너를 거치게 된다.

파티션 지정 여부에 따라 동작방식이 다르다

1. 파티션을 지정 했다면, 파티셔너는 동작하지 않고 해당 파티션으로 레코드를 전달한다.
2. 파티션을 지정 안했다면, 키를 가지고 파티션을 라운드 로빈방식(기본)으로 파티션을 선택해 레코드를 전달한다.

프로듀서는 `send()` 동작 이후에 레코드들을 파티션별로 모아놓고, **배치 전송**을 한다.

전송이 실패하면 지정한 시도횟수 만큼 재시도하고, 실패하면 최종 실패를 전달하며, 성공하면 메타데이터를 리턴한다.

### 3.3.2 프로듀서의 주요 옵션

보통 기본옵션으로 사용해도 문제 없지만, 메시지를 손실 없이 보내거나, 빠르게 전송해야 하는 경우처럼 요구사항에 따라 옵션을 잘 설정하면 효율적이고 안정적으로 사용할 수 있다.

- bootstrap.servers: 카프타 클러스터는 클러스터 마스터 개념이 없어서, 클러스터 내 모든 서버가 클라이언트의 요청을 받을 수 있다. 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트와 포트 정보를 나타낸다.
- client.dns.lookup: 하나의 호스트에서 여러 IP를 매핑해 사용하는 일부 환경에서 클라이언트가 하나의 IP와 연결하지 못할 경우에 다른 IP로 시도하는 설정이다. use_all_dns_ips가 기본값이고, DNS에 할당된 호스트의 모든 IP를 쿼리하고 저장한다. 첫 번쨰 IP로 접근이 실패하면, 종료하지 않고 그 다음 IP로 접근을 시도한다. resolve_canonical_bootstrap_servers_only 옵션은 커버로스(Kerberos) 환경에서 FQDN을 얻기 위한 용도로 사용된다. ???????????
- acks: 프로듀서가 카프카 토픽의 리더 측에 메시지를 전송한 후 요청을 완료하기를 결정하는 옵션이다. 0, 1, all(-1)로 표현하며, 0은 빠른 정송을 의미하지만, 일부 메시지 손실 가능성이 있다. 1은 리더가 메시지를 받았는지 확인하지만, 모든 팔로워를 전부 확인하지는 않는다. 대부분 1을 기본값으로 사용한다. all은 팔로워가 메시지를 받았는지 여부를 확인한다. 다소 느릴 수는 있지만, 하나의 팔로워가 있는 한 메시지는 손실되지 않는다.
- buffer.memory: 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기(배치 전송이나 딜레이 등)할 수 있는 전체 메모리 바이트(byte)이다.
- compression.type: 프로듀서가 메시지 전송 시 선택할 수 있는 압축 타입이다. none, gzip, snappy, lz4, zstd 중 선택할 수 있다.
- enable.idempotence: 설정을 true로 하면 중복 없는 전송이 가능하며, 이와 동시에 max.in.flight.requests.per.connection은 5 이하, retries는 0이상, acks는 all로 설정해야 한다.
- max.in.flight.requests.per.connection: 하나의 커넥션에서 프로듀서가 최대한 ACK 없이 전송할 수 있는 요청 수다. 메시지의 순서가 중요하다면 1로 설정을 권장하지만, 성능은 다소 떨어진다.
- retries: 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수이다.
- batch.size: 프로듀서는 동일한 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도한다. 적절한 배치 크기는 성능에 도움을 준다.
- linger.ms: 이 시간을 지정하면 배치 크기에 도달하지 못한 상황에서도 메시지를 보낼 수 있다.
- transactional.id: '정확히 한번 전송'을 위해 사용하는 옵션이며, 동일한 TransactionalId에 한해 정확히 한 번을 보장한다. 옵션을 사용하기 전 enable.idempotence를 true로 설정해야 한다.

자세한 것은 5장

### 3.3.3 프로듀서 예제

다음과 같이 보낼 수 있다.

- 보내기만 하기
- 동기(보내고 응답받기)
- 비동기(콜백)

# 3.4 컨슈머의 기본 동작과 예제 맛보기

- 컨슈머 그룹, 리밸런싱 등

### 3.4.1 컨슈머의 기본 동작

1. 프로듀서가 카프카 토픽에 메시지를 전송
2. 메시지는 브로커의 로컬 디스크에 저장
3. 카프카 토픽에 저장된 메시지를 컨슈머를 통해서 가져옴.

- 컨슈머 그룹: 하나 이상의 컨슈머들이 모여 있는 그룹. 컨슈머는 반드시 컨슈머 그룹에 속하게 된다.(아니라는 말이 있음) 컨슈머 그룹은 각 파티션 리더에게 메시지를 가져오기 위한 요청을 보냄
- 파티션 수와 컨슈머 수는 1 대 1이 이상적임. 남는 컨슈머는 대기 상태. 장애가 날 경우엔 리밸런싱을 통해 기존 컨슈머들이 남는 파티션을 할당함.

### 3.4.2 컨슈머의 주요 옵션

- bootstrap.servers: 브로커의 정보 입력
- fetch.min.bytes: 한 번에 가져갈 수있는 최소 데이터 크기, 더 작을 경우에 데이터가 누적될 때까지 기다린다.
- group.id: 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자. 동일한 그룹 내의 컨슈머 정보는 모두 공유된다.
- heartbeat.interval.ms: 컨슈머가 살아있는지 브로커에게 알려주는 주기 시간. session.timeout.ms의 1/3.
- max.partition.fetch.bytes: 파티션당 가져올 수 있는 최대 크기
- session.timeout.ms: 세션시간동안 하트비트가 오지 않으면 컨슈머가 종료된 것으로 간주하고 해당 컨슈머를 컨슈머그룹에서 제외하고 리밸런싱을 시작한다.
- enable.auto.commit: 백그라운드로 주기적으로 오프셋을 커밋한다.
- auto.offset.reset: 카프카 오프셋 리셋 조건, 초기 오프셋이나, 현재 오프셋이 없을 경우 다음 옵션에 따라 reset함. earliest: 가장 초기의 오프셋값, latest: 가장 마지막의 오프셋값, none: 이전 오프셋값을 못찾으면 에러
- fetch.max.bytes: 한 번의 가쟈오기 요청으로 가져올 수 있는 최대 크기
- group.instance.id: 컨슈머의 고유한 식별자, 설정하면 static멤버로 간주되어 불필요한 리밸런싱을 하지 않음.
- isolation.level: 트랜잭션 컨슈머에서 사용되는 옵션, read_uncommitted는 기본값으로 모든 메시지를 읽고, read_committed는 트랜잭션이 완료된 메시지만 읽음.
- max.poll.records: 한 번의 poll()요청으로 가져오는 최대 메시지 수.
- partition.assignment.strategy: 파티션 할당 전략, 기본적으론 range.
- fetch.max.wait.ms: fetch.min.bytes에 의한 데이터보다 적은 경우 요청에 대한 응답을 기다리는 최대 시간.

자세한 건 6장

### 3.4.3 컨슈머 예제

크게 3가지 방법이 있다.

- 오토 커밋
- 동기 가져오기(느림, 메시지 손실은 없앨 수 있지만, 중복은 발생)
- 비동기 가져오기(커밋을 비동기로 함, 마지막만 성공해도 다 성공한 것으로 간주, 재시도를 하지 않음, 보완을 위해 콜백 사용)

### 3.4.4 컨슈머 그룹의 이해

컨슈머는 컨슈머 그룹 안에 속한 것이 일반적인 구조다. 컨슈머들은 토픽의 파티션과 일대일로 매핑되어 메시지를 가져온다. 컨슈머들은 서로의 정보를 공유하고, 하나가 문제가 생겨 종료되면 나머지 컨슈머들 중 하나가 종료된 컨슈머의 토픽의 파티션을 컨슘한다.

# 3.5 정리
